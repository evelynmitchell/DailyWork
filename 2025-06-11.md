
# todo

[ ] github notifications
[]   github dashboard
[- ] https://claude.ai/chat/d12488c0-1c09-447d-9f00-cef7cff1b64c
[ ] https://colab.research.google.com/drive/1DsJGiHywjWbGAIpSJkbxKPN1X10kSiHi
[ ] wardley mapping
[ ] https://github.com/the-pocket/PocketFlow
[ ] metaflow eval
[ ] P explainer write
[ ] V FIX
[ ] R Alpha
[ ] value app
[ ] workflows for gumloop or kestra
[/ ] evelynmitchell/async_python_testing_tutorial - get asynchronous tests running
[ ] evelynmitchell/TemplateUpdateRepos
[ ] aap https://agentlaboratory.github.io/ and https://arxiv.org/pdf/2409.12516 A Multi-agent Market Model Can Explain the Impact of AI Traders in Financial Markets – A New Microfoundations of GARCH model
[ ] docs on creating SEAL https://github.com/evelynmitchell/SEAL-js
[ ] write agents for https://github.com/evelynmitchell/AgentHands |
[ ] Weekly Business Review - yaml (hypothesis, dag, metrics)
[ ] modern GAN () - could work more on readme, inference, data gen, training tools
[ ] https://github.com/evelynmitchell/sophie
[ ] https://github.com/evelynmitchell/bootstrapFlywheel
[ ] set up multiagent debate training setup with phi4/ollama
[ ] https://github.com/evelynmitchell/lightning-attention CUDA, Triton
[ ] https://transformerlab.ai/docs/faq
[ ] flippable card layout https://claude.ai/chat/27b8d33a-fe75-46bb-ad15-c95f6448a329
[ ] wasm tutorial - flutter/dart https://webassembly.org/getting-started/developers-guide/ https://github.com/bytecodealliance/wasmtime/blob/main/docs/WASI-tutorial.md
[ ] gensx hello world
[ ] https://diffusion.csail.mit.edu/ flow matching 
[ ] https://github.com/danielmiessler/fabric hello world, container
[ ] https://fizzbee.io/ work examples
[ ] https://arxiv.org/abs/2405.02318 NL2FOL
https://youtu.be/kwIAR_OO-3Y?feature=shared&t=3607
[ ] openbb https://colab.research.google.com/drive/1uqeyvUt9a5QjrVNj3Qf049wZqVjyHDuC https://colab.research.google.com/drive/1lCVV19hv39T69SLbkmEV6DKrqHDUz4hX#scrollTo=GWI_60zD3M3l https://colab.research.google.com/drive/1sePIH3GuhdMPlpDhEmN8TCxOsut6pUJI#scrollTo=t1SRywKlq7Kr
[ ]  https://www.bollingerbands.com/market-timing-charts Friday
[ ] https://github.com/eyaltoledano/claude-task-master
[ ] https://academy.picussecurity.com/path-player?courseid=cyber-threat-intelligence&unit=660d46a0362ed7588909a2c5Unit
[ ] sornette https://colab.research.google.com/drive/10DZXjwh1kjHrJ-guSW6UZdXT43fL0K4p#scrollTo=5F180JBDvYdr
[ ] https://github.com/clockworklabs/SpacetimeDB https://spacetimedb.com/docs 
[ ] https://github.com/NVIDIA/cuda-python
[ ] https://arxiv.org/abs/2502.19983 #timeseries 
[ ] https://github.com/evelynmitchell/toraniko eval
[ ] https://colab.research.google.com/drive/1aFj4yGLG_cuSmp6EbWwa_guc_jsFYYiD Gaussian process regression
[/ ] RL julia https://colab.research.google.com/drive/147KcuJhch_JEZpCqInZ9io9uPdGtlXrm
# done
[ ] github notifications
[]   github dashboard
[- ] https://claude.ai/chat/d12488c0-1c09-447d-9f00-cef7cff1b64c 1898 2008  1711 2006
[ ] https://colab.research.google.com/drive/1DsJGiHywjWbGAIpSJkbxKPN1X10kSiHi
# links

https://h4x.zip/

https://mattweidner.com/2025/05/21/text-without-crdts.html #crdt 

https://advicenotes.blogspot.com/2012/07/daniel-e-greene-palette.html #color  #palette

https://www.quantkiosk.com/

https://arxiv.org/abs/2407.16212v1 Optimal experimental design: Formulations and computations "Optimal experimental design (OED) formalizes these questions and creates computational methods to answer them. This article presents a systematic survey of modern OED, from its foundations in classical design theory to current research involving OED for complex models. We begin by reviewing criteria used to formulate an OED problem and thus to encode the goal of performing an experiment. We emphasize the flexibility of the Bayesian and decision-theoretic approach, which encompasses information-based criteria that are well-suited to nonlinear and non-Gaussian statistical models. We then discuss methods for estimating or bounding the values of these design criteria; this endeavor can be quite challenging due to strong nonlinearities, high parameter dimension, large per-sample costs, or settings where the model is implicit. A complementary set of computational issues involves optimization methods used to find a design; we discuss such methods in the discrete (combinatorial) setting of observation selection and in settings where an exact design can be continuously parameterized. Finally we present emerging methods for sequential OED that build non-myopic design policies, rather than explicit designs; these methods naturally adapt to the outcomes of past experiments in proposing new experiments, while seeking coordination among all experiments to be performed. Throughout, we highlight important open questions and challenges."

\https://arxiv.org/abs/2203.15556 Training Compute-Optimal Large Language Models " We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4![](https://static.arxiv.org/MathJax-2.7.3/fonts/HTML-CSS/TeX/png/Main/Regular/336/00D7.png?V=2.7.3) more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher."

https://posthog.com/deskhog

https://bsky.app/profile/samuelpepys.bsky.social

https://github.com/good-lly/s3mini #s3
"libcurl also has AWS auth with --aws-sigv4 which gives you a fully compatible S3 cliënt without installing anything! (You probably already have curl installed)" https://news.ycombinator.com/item?id=44249093

https://popularpays.com/ #b2c

https://github.com/zephyrproject-rtos/zephyr #rtos 
# agent prompts



# daily work review

# weekly work review