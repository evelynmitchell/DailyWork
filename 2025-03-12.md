# todo
[  ] https://claude.ai/chat/d12488c0-1c09-447d-9f00-cef7cff1b64c
[ ] wardley mapping
[ -] paper group ()
[ ] github notifications
[]  ] github dashboard
[/ ] can pp
[/ ] brainstorming
   [ ] card sort
[ ] linda card
[ /] taxes?
[ ] P explainer write
[ ] MCP explainer write
[ ] V FIX
[ ] R Alpha
[ ] value app
[ ] OpenHands project prompts in .openhands_instructions
[ ] swagger.yaml -> markdown github action
[/ ] server setup
[ ] workflows for gumloop or kestra
[/ ] cleanup github forked repos
[/ ] evelynmitchell/async_python_testing_tutorial - get asynchronous tests running
[ ] evelynmitchell/TemplateUpdateRepos
[ ] aap https://agentlaboratory.github.io/ and https://arxiv.org/pdf/2409.12516 A Multi-agent Market Model Can Explain the Impact of AI Traders in Financial Markets â€“ A New Microfoundations of GARCH model
[ ] docs on creating SEAL https://github.com/evelynmitchell/SEAL-js
[ ] write agents for https://github.com/evelynmitchell/AgentHands |
[ ] open ticket to test swarms with https://github.com/TheAgentCompany/TheAgentCompany
[ ] Weekly Business Review - yaml (hypothesis, dag, metrics)
[ ] modern GAN () - could work more on readme, inference, data gen, training tools
[ ] https://github.com/evelynmitchell/sophie
[ ] https://github.com/evelynmitchell/bootstrapFlywheel
[ ] set up multiagent debate training setup with phi4/ollama
[ ] https://github.com/evelynmitchell/lightning-attention CUDA, Triton
[ ] https://transformerlab.ai/docs/faq
[ ] flippable card layout https://claude.ai/chat/27b8d33a-fe75-46bb-ad15-c95f6448a329
[ ] wasm tutorial - flutter/dart
[ ] gensx hello world
[ ] https://diffusion.csail.mit.edu/ flow matching 
[ ] https://github.com/danielmiessler/fabric hello world, container
[ ] https://fizzbee.io/ work examples
[ ] https://github.com/evelynmitchell/swarms-evals
[ ] https://arxiv.org/abs/2405.02318 NL2FOL
https://youtu.be/kwIAR_OO-3Y?feature=shared&t=3607

# done

[  ] https://claude.ai/chat/d12488c0-1c09-447d-9f00-cef7cff1b64c 2001
[ ] github notifications
[ ] github dashboard



# links

https://arxiv.org/pdf/2503.05703 What I cannot execute, I do not understand: Training and Evaluating LLMs on Program Execution Traces
Code generation and understanding are critical capabilities for large language models (LLMs). Thus, most LLMs are pretrained and fine-tuned on code data. However, these datasets typically treat code as static strings and rarely exploit the dynamic information about their execution. Building upon previous work on trace modeling, we study Execution Tuning (E.T.), a training procedure in which we explicitly model real-world program execution traces without requiring manual test annotations. We train and evaluate models on different execution trace granularities (line and instruction-level) and strategies on the task of output prediction, obtaining around 80% accuracy on CruxEval and MBPP, and showing the advantages of dynamic scratchpads (i.e., self-contained intermediate computations updated by the model rather than accumulated as a history of past computations) on long executions (up to 14k steps). Finally, we discuss E.T.'s practical applications.
![[Screenshot from 2025-03-12 10-52-02.png]]
![[Screenshot from 2025-03-12 10-52-53.png]]
#python sys.settrace https://docs.python.org/3/library/sys.html#sys.settrace https://www.geeksforgeeks.org/python-sys-settrace/ https://docs.python.org/3/library/sys.html#sys.gettrace https://stackoverflow.com/questions/38634988/check-if-program-runs-in-debug-mode

https://github.com/marketplace/actions/social-post https://github.com/lwojcik/github-action-feed-to-social-media https://github.com/nhoizey/github-action-feed-to-mastodon

https://sugaku.net/content/understanding-the-cultural-divide-between-mathematics-and-ai/

# agent prompts

# daily work review

# weekly work review