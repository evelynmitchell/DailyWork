# todo
[ ] https://claude.ai/chat/d12488c0-1c09-447d-9f00-cef7cff1b64c
[ ] wardley mapping
[ -] paper group ()
[] github notifications
[ ] github dashboard
[ ] OpenHands project prompts in .openhands_instructions
[ ] swagger.yaml -> markdown github action
[/ ] server setup
[ ] workflows for gumloop or kestra
[/ ] cleanup github forked repos
[/ ] evelynmitchell/async_python_testing_tutorial - get asynchronous tests running
[ ] evelynmitchell/TemplateUpdateRepos
[ ] aap https://agentlaboratory.github.io/ and https://arxiv.org/pdf/2409.12516 A Multi-agent Market Model Can Explain the Impact of AI Traders in Financial Markets – A New Microfoundations of GARCH model
[ ] docs on creating SEAL https://github.com/evelynmitchell/SEAL-js
[ ] write agents for https://github.com/evelynmitchell/AgentHands |
[ ] open ticket to test swarms with https://github.com/TheAgentCompany/TheAgentCompany
[ ] Weekly Business Review - yaml (hypothesis, dag, metrics)
[ ] modern GAN () - could work more on readme, inference, data gen, training tools
[ ] https://github.com/evelynmitchell/sophie
[ ] https://github.com/evelynmitchell/bootstrapFlywheel
[ ] set up multiagent debate training setup with phi4/ollama
[ ] https://github.com/evelynmitchell/lightning-attention CUDA, Triton

# done
[ -] paper group ()
https://arxiv.org/abs/2408.03314 Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters ; DeepMind ; "v\if an
LLM is allowed to use a fixed but non-trivial amount of inference-time compute, how much can it improve its
performance on a challenging prompt? " "In this work, we analyze two primary mechanisms to scale test-time
computation: (1) searching against dense, process-based verifier reward models; and (2) updating the
model’s distribution over a response adaptively, given the prompt at test time"
rguably the simplest
and most well-studied approach for scaling test-time computation is best-of-N sampling: sampling N
outputs in “parallel” from a base LLM and selecting the one that scores the highest per a learned verifier
or a reward model
By modifying either the *proposal distribution* from which responses are obtained (for
instance, by asking the base model to revise its original responses “sequentially” [28 ]) or by altering how
the *verifier* is used (e.g. by training a process-based dense verifier [ 22 , 45 ] and searching against this
verifier), the ability scale test-time compute could be greatly improved, as we show in the paper.

Takeaways for compute-optimal scaling of verifiers
We find that the efficacy of any given verifier search method depends critically on both the compute
budget and the question at hand. Specifically, beam-search is more effective on harder questions
and at lower compute budgets, whereas best-of-N is more effective on easier questions and at higher
budgets. Moreover, by selecting the best search setting for a given question difficulty and test-time
compute budget, we can nearly outperform best-of-N using up to 4x less test-time compute


https://arxiv.org/abs/2501.19393 s1: Simple test-time scaling ; https://github.com/simplescaling/s1 very detailed methods

[x] github notifications

[ x] github dashboard
[x ] https://claude.ai/chat/d12488c0-1c09-447d-9f00-cef7cff1b64c 1673
[x] team meeting

https://github.com/evelynmitchell/hibiki

https://lovable.dev/projects/dea000a0-8869-441e-a432-d5156eb13492
https://docs.lovable.dev/integrations/supabase
https://supabase.com/dashboard/project/beyulssducmkclsmaxhv/storage/buckets

# team meeting
deepseek
pubsub
gpro
agent filters
videos
# links

https://www.khoury.northeastern.edu/~pete/pub/sat-cnf.pdf Efficient Circuit to CNF Conversion ; Abstract. Modern SAT solvers are proficient at solving Boolean satisfiability problems in Conjunctive Normal Form (CNF). However, these
problems mostly arise from general Boolean circuits that are then translated to CNF. We outline a simple and expressive data structure for
describing arbitrary circuits, as well as an algorithm for converting circuits to CNF. Our experimental results over a large benchmark suite
show that the CNF problems we generate are consistently smaller and
more quickly solved by modern SAT solvers than the CNF problems
generated by current CNF generation methods.
![[Screenshot from 2025-02-06 14-13-35.png]]
![[Screenshot from 2025-02-06 14-14-16.png]]
https://en.wikipedia.org/wiki/Tseytin_transformation

https://github.com/evelynmitchell/hibiki

https://pulsar.apache.org/

https://supabase.com/docs/guides/realtime/architecture

https://hexdocs.pm/phoenix/channels.html

https://hexdocs.pm/phoenix_pubsub/Phoenix.PubSub.html

Reinforcement learning class https://web.stanford.edu/class/cs234/CS234Spr2024/index.html 


https://pyvigate.readthedocs.io/en/latest/ headless browser

https://chshersh.com/blog/2024-07-30-pragmatic-category-theory-part-01.html
A **semigroup** is a pair of a type and an operation of appending two values of this type to get a third value of the same type. Category Theory definition: a _semigroup_ is a hom-set in a semicategory with a single object.
The operation must be associative.
a **semigroup** is a pair of type `t` and a binary associative operation where the operands and the result all have the same type `t`.

https://chshersh.com/blog/2024-08-19-pragmatic-category-theory-part-02.html 
https://chshersh.com/blog/2024-12-20-pragmatic-category-theory-part-03.html

https://en.wikipedia.org/wiki/Treap In [computer science](https://en.wikipedia.org/wiki/Computer_science "Computer science"), the **treap** and the **randomized binary search tree** are two closely related forms of binary search tree [data structures](https://en.wikipedia.org/wiki/Data_structure "Data structure") that maintain a dynamic set of ordered keys and allow [binary searches](https://en.wikipedia.org/wiki/Binary_search "Binary search") among the keys. After any sequence of insertions and deletions of keys, the shape of the tree is a random variable with the same probability distribution as a random binary tree; in particular, [with high probability](https://en.wikipedia.org/wiki/With_high_probability "With high probability") its height is proportional to the [logarithm](https://en.wikipedia.org/wiki/Logarithm "Logarithm") of the number of keys, so that each search, insertion, or deletion operation takes logarithmic time to perform.

https://eqbench.com/creative_writing.html #evals 
https://github.com/ahstat/episodic-memory-benchmark #evals #### A framework for measuring how well LLMs can encode, store, and recall episodic events across extended narratives.
# agent prompts

# daily work review

# weekly work review
