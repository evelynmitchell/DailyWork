Paper Group

	https://arxiv.org/pdf/2412.00154
	
	https://arxiv.org/pdf/2412.01199 | https://github.com/VainF/TinyFusion
	https://arxiv.org/abs/2412.01822
	![[Screenshot from 2024-12-03 08-29-26.png]]
	![[Screenshot from 2024-12-03 08-30-23.png]]
	![[Screenshot from 2024-12-03 08-33-09.png]]
	
"The verbalizer consists of a simple FFN [85] and the language head from the
backbone VLM. To distinguish between FFN components,
we refer to the FFN within the verbalizer as “verb-FFN” to
avoid confusion with the FFN in the LLM transformer decoder block. This design is inspired by the recent speculative decoding paradigm [55], which demonstrates the effectiveness of using a smaller LLM constructed with a frozen
word embedding and the language head of larger LLMs to
emulate the performance of those larger models. Building
on this insight, we incorporate the language head of the
backbone VLM into its intermediate layers. Specifically,
the verb-FFN is placed between each intermediate layer and
the language head, introducing trainable parameters that allow effective projection into the language space. In other
words, the verb-FFN enables outputs from the intermediate layers to project to the language space via the language
head."

Swarms testing https://colab.research.google.com/drive/1KmgPCeAVVlez-saXIg7-bbq_9nm3Rqdj
