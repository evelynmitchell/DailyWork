
# todo

[ ] github notifications
[]   github dashboard
[- ] https://claude.ai/chat/d12488c0-1c09-447d-9f00-cef7cff1b64c
[ ] https://colab.research.google.com/drive/1DsJGiHywjWbGAIpSJkbxKPN1X10kSiHi
[ ] wardley mapping
[ ] https://github.com/the-pocket/PocketFlow
[ ] metaflow eval
[ ] P explainer write
[ ] V FIX
[ ] R Alpha
[ ] value app
[ ] workflows for gumloop or kestra
[/ ] evelynmitchell/async_python_testing_tutorial - get asynchronous tests running
[ ] evelynmitchell/TemplateUpdateRepos
[ ] aap https://agentlaboratory.github.io/ and https://arxiv.org/pdf/2409.12516 A Multi-agent Market Model Can Explain the Impact of AI Traders in Financial Markets â€“ A New Microfoundations of GARCH model
[ ] docs on creating SEAL https://github.com/evelynmitchell/SEAL-js
[ ] write agents for https://github.com/evelynmitchell/AgentHands |
[ ] Weekly Business Review - yaml (hypothesis, dag, metrics)
[ ] modern GAN () - could work more on readme, inference, data gen, training tools
[ ] https://github.com/evelynmitchell/sophie
[ ] https://github.com/evelynmitchell/bootstrapFlywheel
[ ] set up multiagent debate training setup with phi4/ollama
[ ] https://github.com/evelynmitchell/lightning-attention CUDA, Triton
[ ] https://transformerlab.ai/docs/faq
[ ] flippable card layout https://claude.ai/chat/27b8d33a-fe75-46bb-ad15-c95f6448a329
[ ] wasm tutorial - flutter/dart https://webassembly.org/getting-started/developers-guide/ https://github.com/bytecodealliance/wasmtime/blob/main/docs/WASI-tutorial.md
[ ] gensx hello world
[ ] https://diffusion.csail.mit.edu/ flow matching 
[ ] https://github.com/danielmiessler/fabric hello world, container
[ ] https://fizzbee.io/ work examples
[ ] https://arxiv.org/abs/2405.02318 NL2FOL
https://youtu.be/kwIAR_OO-3Y?feature=shared&t=3607
[ ] openbb https://colab.research.google.com/drive/1uqeyvUt9a5QjrVNj3Qf049wZqVjyHDuC https://colab.research.google.com/drive/1lCVV19hv39T69SLbkmEV6DKrqHDUz4hX#scrollTo=GWI_60zD3M3l https://colab.research.google.com/drive/1sePIH3GuhdMPlpDhEmN8TCxOsut6pUJI#scrollTo=t1SRywKlq7Kr
[ ]  https://www.bollingerbands.com/market-timing-charts Friday
[ ] https://github.com/eyaltoledano/claude-task-master
[ ] https://academy.picussecurity.com/path-player?courseid=cyber-threat-intelligence&unit=660d46a0362ed7588909a2c5Unit
[ ] sornette https://colab.research.google.com/drive/10DZXjwh1kjHrJ-guSW6UZdXT43fL0K4p#scrollTo=5F180JBDvYdr
[ ] https://github.com/clockworklabs/SpacetimeDB https://spacetimedb.com/docs 
[ ] https://github.com/NVIDIA/cuda-python
[ ] https://arxiv.org/abs/2502.19983 #timeseries 
[ ] https://github.com/evelynmitchell/toraniko eval
[ ] https://colab.research.google.com/drive/1aFj4yGLG_cuSmp6EbWwa_guc_jsFYYiD Gaussian process regression
[/ ] RL julia https://colab.research.google.com/drive/147KcuJhch_JEZpCqInZ9io9uPdGtlXrm
# done
# links

https://tryapl.org/

https://gridap.github.io/GridapSolvers.jl/stable/ #julia #solver 

https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode

https://arxiv.org/abs/2506.10943 Self-Adapting Language Models "Large language models (LLMs) are powerful but static; they lack mechanisms to adapt their weights in response to new tasks, knowledge, or examples. We introduce Self-Adapting LLMs (SEAL), a framework that enables LLMs to self-adapt by generating their own finetuning data and update directives. Given a new input, the model produces a self-edit-a generation that may restructure the information in different ways, specify optimization hyperparameters, or invoke tools for data augmentation and gradient-based updates. Through supervised finetuning (SFT), these self-edits result in persistent weight updates, enabling lasting adaptation. To train the model to produce effective self-edits, we use a reinforcement learning loop with the downstream performance of the updated model as the reward signal. Unlike prior approaches that rely on separate adaptation modules or auxiliary networks, SEAL directly uses the model's own generation to control its adaptation process. Experiments on knowledge incorporation and few-shot generalization show that SEAL is a promising step toward language models capable of self-directed adaptation. Our website and code is available at this https URL. " https://jyopari.github.io/posts/seal https://github.com/Continual-Intelligence https://github.com/Continual-Intelligence/SEAL

https://www.nhatcher.com/post/on-hats-and-sats/ https://en.wikipedia.org/wiki/Tseytin_transformation #SAT "The **Tseytin transformation**, alternatively written **Tseitin transformation**, takes as input an arbitrary [combinatorial logic](https://en.wikipedia.org/wiki/Combinational_logic "Combinational logic") circuit and produces an [equisatisfiable](https://en.wikipedia.org/wiki/Equisatisfiable "Equisatisfiable") boolean formula in [conjunctive normal form](https://en.wikipedia.org/wiki/Conjunctive_normal_form "Conjunctive normal form") (CNF). The length of the formula is linear in the size of the circuit. Input vectors that make the circuit output "true" are in [1-to-1 correspondence](https://en.wikipedia.org/wiki/Bijection "Bijection") with assignments that satisfy the formula. This reduces the problem of [circuit satisfiability](https://en.wikipedia.org/wiki/Circuit_satisfiability "Circuit satisfiability") on any circuit (including any formula) to the [satisfiability problem](https://en.wikipedia.org/wiki/Boolean_satisfiability_problem "Boolean satisfiability problem") on 3-CNF formulas. It was discovered by the Russian scientist [Grigori Tseitin](https://en.wikipedia.org/wiki/Grigori_Tseitin "Grigori Tseitin")." https://www.decision-procedures.org/handouts/Tseitin70.pdf #logic https://github.com/mauzigoe/tseitin_cli https://btmc.substack.com/p/implementing-logic-programming m
# agent prompts

# daily work review

# weekly work review